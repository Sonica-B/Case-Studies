version: '3.8'

services:
  # API-based Product
  ml-api:
    build:
      context: .
      dockerfile: Dockerfile.api
      args:
        - BUILDKIT_INLINE_CACHE=1
    image: ${DOCKER_REGISTRY:-ghcr.io}/${GITHUB_REPOSITORY:-ml-products}/ml-api:${IMAGE_TAG:-latest}
    container_name: ml-api-product
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=5000
      - PROMETHEUS_MULTIPROC_DIR=/tmp
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    ports:
      - "${API_GRADIO_PORT:-5000}:5000"
      - "${API_METRICS_PORT:-8000}:8000"
      - "${API_NODE_EXPORTER_PORT:-9100}:9100"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - ml-network
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=8000"
      - "prometheus.io/path=/metrics"

  # Locally Executed Product
  ml-local:
    build:
      context: .
      dockerfile: Dockerfile.local
      args:
        - BUILDKIT_INLINE_CACHE=1
    image: ${DOCKER_REGISTRY:-ghcr.io}/${GITHUB_REPOSITORY:-ml-products}/ml-local:${IMAGE_TAG:-latest}
    container_name: ml-local-product
    environment:
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=5003
      - PROMETHEUS_MULTIPROC_DIR=/tmp
      - TORCH_HOME=/models
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    ports:
      - "${LOCAL_GRADIO_PORT:-5003}:5003"
      - "${LOCAL_METRICS_PORT:-8001}:8000"
      - "${LOCAL_NODE_EXPORTER_PORT:-9101}:9100"
    volumes:
      - model-cache:/models
      - model-cache:/root/.cache/huggingface
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5003"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - ml-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=8000"
      - "prometheus.io/path=/metrics"

  # Prometheus Server
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=${PROMETHEUS_RETENTION:-15d}'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    ports:
      - "${PROMETHEUS_PORT:-5006}:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ml-network
    restart: unless-stopped
    depends_on:
      ml-api:
        condition: service_healthy
      ml-local:
        condition: service_healthy

  # Grafana Server
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=${GRAFANA_PLUGINS:-}
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL:-http://localhost:5007}
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_SECURITY_ALLOW_EMBEDDING=true
    ports:
      - "${GRAFANA_PORT:-5007}:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ml-network
    restart: unless-stopped
    depends_on:
      prometheus:
        condition: service_healthy

  # Ngrok for API Product (Optional)
  ngrok-api:
    image: ngrok/ngrok:alpine
    container_name: ngrok-api
    command:
      - "http"
      - "ml-api:5000"
      - "--authtoken=${NGROK_AUTHTOKEN}"
      - "--domain=${NGROK_API_DOMAIN:-}"
      - "--log=stdout"
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN}
    networks:
      - ml-network
    restart: unless-stopped
    depends_on:
      ml-api:
        condition: service_healthy
    profiles:
      - ngrok

  # Ngrok for Local Product (Optional)
  ngrok-local:
    image: ngrok/ngrok:alpine
    container_name: ngrok-local
    command:
      - "http"
      - "ml-local:5003"
      - "--authtoken=${NGROK_AUTHTOKEN}"
      - "--domain=${NGROK_LOCAL_DOMAIN:-}"
      - "--log=stdout"
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN}
    networks:
      - ml-network
    restart: unless-stopped
    depends_on:
      ml-local:
        condition: service_healthy
    profiles:
      - ngrok

  # Ngrok for Grafana (Optional)
  ngrok-grafana:
    image: ngrok/ngrok:alpine
    container_name: ngrok-grafana
    command:
      - "http"
      - "grafana:3000"
      - "--authtoken=${NGROK_AUTHTOKEN}"
      - "--domain=${NGROK_GRAFANA_DOMAIN:-}"
      - "--log=stdout"
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN}
    networks:
      - ml-network
    restart: unless-stopped
    depends_on:
      grafana:
        condition: service_healthy
    profiles:
      - ngrok

networks:
  ml-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  model-cache:
    driver: local
